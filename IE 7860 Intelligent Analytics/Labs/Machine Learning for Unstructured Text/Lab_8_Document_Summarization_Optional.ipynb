{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8_Document_Summarization_Optional.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIMsr2fPxRCr"
      },
      "source": [
        "## **Assignment - 8 (Optional): Document Summarization** \n",
        "### ID: eo9232\n",
        "### Name: Md Reza\n",
        "### IE7860 - Winter 2022"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw33Qd4NhWKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69261050-0b21-4f9c-d211-b28f127f5e39"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import bs4 as bs\n",
        "import urllib.request as url\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import heapq\n",
        "from string import punctuation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scrape & Load The Article**\n",
        "#### Source: https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)"
      ],
      "metadata": {
        "id": "slSrtKQ6st2x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqJGxDS5heba"
      },
      "source": [
        "data_scraped = url.urlopen('https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)')\n",
        "article = data_scraped.read()\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOazmqJmhvC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7550e9b8-ded7-46f4-9034-6c1abe6d75c8"
      },
      "source": [
        "article_text"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data. It is used primarily in the fields of natural language processing (NLP)[1] and computer vision (CV).[2]\\nLike recurrent neural networks (RNNs), transformers are designed to handle sequential input data, such as natural language, for tasks such as translation and text summarization. However, unlike RNNs, transformers do not necessarily process the data in order. Rather, the attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence, the transformer does not need to process the beginning of the sentence before the end. Rather it identifies the context that confers meaning to each word in the sentence. This feature allows for more parallelization than RNNs and therefore reduces training times.[1]\\nTransformers were introduced in 2017 by a team at Google Brain[1] and are increasingly the model of choice for NLP problems,[3] replacing RNN models such as long short-term memory (LSTM). The additional training parallelization allows training on larger datasets than was once possible. This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl, and can be fine-tuned for specific tasks.[4][5]\\nBefore transformers, most state-of-the-art NLP systems relied on gated RNNs, such as LSTM and gated recurrent units (GRUs), with added attention mechanisms. Transformers are built on these attention technologies without using an RNN structure, highlighting the fact that attention mechanisms alone can match the performance of RNNs with attention.\\nGated RNNs process tokens sequentially, maintaining a state vector that contains a representation of the data seen after every token. To process the \\n\\n\\n\\nn\\n\\n\\n{\\\\textstyle n}\\n\\nth token, the model combines the state representing the sentence up to token \\n\\n\\n\\nn\\n−\\n1\\n\\n\\n{\\\\textstyle n-1}\\n\\n with the information of the new token to create a new state, representing the sentence up to token \\n\\n\\n\\nn\\n\\n\\n{\\\\textstyle n}\\n\\n. Theoretically, the information from one token can propagate arbitrarily far down the sequence, if at every point the state continues to encode contextual information about the token. In practice this mechanism is flawed: the vanishing gradient problem leaves the model\\'s state at the end of a long sentence without precise, extractable information about preceding tokens.\\nThe dependency of token computations on results of previous token computations also makes it hard to parallelize computation on modern deep learning hardware. This can make the training of RNNs inefficient.\\nThese problems were addressed by attention mechanisms. Attention mechanisms let a model draw from the state at any preceding point along the sequence. The attention layer can access all previous states and weigh them according to a learned measure of relevancy, providing relevant information about far-away tokens.\\nA clear example of the value of attention is in language translation, where context is essential to assign the meaning of a word in a sentence. In an English-to-French translation system, the first word of the French output most probably depends heavily on the first few words of the English input. However, in a classic LSTM model, in order to produce the first word of the French output, the model is given only the state vector of the last English word. Theoretically, this vector can encode information about the whole English sentence, giving the model all necessary knowledge. In practice, this information is often poorly preserved by the LSTM. An attention mechanism can be added to address this problem: the decoder is given access to the state vectors of every English input word, not just the last, and can learn attention weights that dictate how much to attend to each English input state vector.\\nWhen added to RNNs, attention mechanisms increase performance. The development of the Transformer architecture revealed that attention mechanisms were powerful in themselves and that sequential recurrent processing of data was not necessary to achieve the quality gains of RNNs with attention. Transformers use an attention mechanism without an RNN, processing all tokens at the same time and calculating attention weights between them in successive layers.\\nSince the attention mechanism only uses information about other tokens from lower layers, it can be computed for all tokens in parallel, which leads to improved training speed.\\nLike earlier seq2seq models, the original Transformer model used an encoder-decoder architecture. The encoder consists of encoding layers that process the input iteratively one layer after another, while the decoder consists of decoding layers that do the same thing to the encoder\\'s output.\\nThe function of each encoder layer is to generate encodings that contain information about which parts of the inputs are relevant to each other. It passes its encodings to the next encoder layer as inputs. Each decoder layer does the opposite, taking all the encodings and using their incorporated contextual information to generate an output sequence.[6] To achieve this, each encoder and decoder layer makes use of an attention mechanism.\\nFor each input, attention weighs the relevance of every other input and draws from them to produce the output.[7] Each decoder layer has an additional attention mechanism that draws information from the outputs of previous decoders, before the decoder layer draws information from the encodings.\\nBoth the encoder and decoder layers have a feed-forward neural network for additional processing of the outputs and contain residual connections and layer normalization steps.[7]\\nThe transformer building blocks are scaled dot-product attention units. When a sentence is passed into a transformer model, attention weights are calculated between every token simultaneously. The attention unit produces embeddings for every token in context that contain information about the token itself along with a weighted combination of other relevant tokens each weighted by its attention weight.\\nFor each attention unit the transformer model learns three weight matrices; the query weights \\n\\n\\n\\n\\nW\\n\\nQ\\n\\n\\n\\n\\n{\\\\displaystyle W_{Q}}\\n\\n, the key weights \\n\\n\\n\\n\\nW\\n\\nK\\n\\n\\n\\n\\n{\\\\displaystyle W_{K}}\\n\\n, and the value weights \\n\\n\\n\\n\\nW\\n\\nV\\n\\n\\n\\n\\n{\\\\displaystyle W_{V}}\\n\\n. For each token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n, the input word embedding \\n\\n\\n\\n\\nx\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle x_{i}}\\n\\n is multiplied with each of the three weight matrices to produce a query vector \\n\\n\\n\\n\\nq\\n\\ni\\n\\n\\n=\\n\\nx\\n\\ni\\n\\n\\n\\nW\\n\\nQ\\n\\n\\n\\n\\n{\\\\displaystyle q_{i}=x_{i}W_{Q}}\\n\\n, a key vector \\n\\n\\n\\n\\nk\\n\\ni\\n\\n\\n=\\n\\nx\\n\\ni\\n\\n\\n\\nW\\n\\nK\\n\\n\\n\\n\\n{\\\\displaystyle k_{i}=x_{i}W_{K}}\\n\\n, and a value vector \\n\\n\\n\\n\\nv\\n\\ni\\n\\n\\n=\\n\\nx\\n\\ni\\n\\n\\n\\nW\\n\\nV\\n\\n\\n\\n\\n{\\\\displaystyle v_{i}=x_{i}W_{V}}\\n\\n. Attention weights are calculated using the query and key vectors: the attention weight \\n\\n\\n\\n\\na\\n\\ni\\nj\\n\\n\\n\\n\\n{\\\\displaystyle a_{ij}}\\n\\n from token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n to token \\n\\n\\n\\nj\\n\\n\\n{\\\\displaystyle j}\\n\\n is the dot product between \\n\\n\\n\\n\\nq\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle q_{i}}\\n\\n and \\n\\n\\n\\n\\nk\\n\\nj\\n\\n\\n\\n\\n{\\\\displaystyle k_{j}}\\n\\n. The attention weights are divided by the square root of the dimension of the key vectors, \\n\\n\\n\\n\\n\\n\\nd\\n\\nk\\n\\n\\n\\n\\n\\n\\n{\\\\displaystyle {\\\\sqrt {d_{k}}}}\\n\\n, which stabilizes gradients during training, and passed through a softmax which normalizes the weights. The fact that \\n\\n\\n\\n\\nW\\n\\nQ\\n\\n\\n\\n\\n{\\\\displaystyle W_{Q}}\\n\\n and \\n\\n\\n\\n\\nW\\n\\nK\\n\\n\\n\\n\\n{\\\\displaystyle W_{K}}\\n\\n are different matrices allows attention to be non-symmetric: if token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n attends to token \\n\\n\\n\\nj\\n\\n\\n{\\\\displaystyle j}\\n\\n (i.e. \\n\\n\\n\\n\\nq\\n\\ni\\n\\n\\n⋅\\n\\nk\\n\\nj\\n\\n\\n\\n\\n{\\\\displaystyle q_{i}\\\\cdot k_{j}}\\n\\n is large), this does not necessarily mean that token \\n\\n\\n\\nj\\n\\n\\n{\\\\displaystyle j}\\n\\n will attend to token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n (i.e. \\n\\n\\n\\n\\nq\\n\\nj\\n\\n\\n⋅\\n\\nk\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle q_{j}\\\\cdot k_{i}}\\n\\n could be small).  The output of the attention unit for token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n is the weighted sum of the value vectors of all tokens, weighted by \\n\\n\\n\\n\\na\\n\\ni\\nj\\n\\n\\n\\n\\n{\\\\displaystyle a_{ij}}\\n\\n, the attention from token \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\n to each token.\\nThe attention calculation for all tokens can be expressed as one large matrix calculation using the softmax function, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices \\n\\n\\n\\nQ\\n\\n\\n{\\\\displaystyle Q}\\n\\n, \\n\\n\\n\\nK\\n\\n\\n{\\\\displaystyle K}\\n\\n and \\n\\n\\n\\nV\\n\\n\\n{\\\\displaystyle V}\\n\\n are defined as the matrices where the \\n\\n\\n\\ni\\n\\n\\n{\\\\displaystyle i}\\n\\nth rows are vectors \\n\\n\\n\\n\\nq\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle q_{i}}\\n\\n, \\n\\n\\n\\n\\nk\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle k_{i}}\\n\\n, and \\n\\n\\n\\n\\nv\\n\\ni\\n\\n\\n\\n\\n{\\\\displaystyle v_{i}}\\n\\n respectively.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAttention\\n\\n(\\nQ\\n,\\nK\\n,\\nV\\n)\\n=\\n\\nsoftmax\\n\\n\\n(\\n\\n\\n\\nQ\\n\\nK\\n\\n\\nT\\n\\n\\n\\n\\n\\n\\nd\\n\\nk\\n\\n\\n\\n\\n\\n)\\n\\nV\\n\\n\\n\\n\\n\\n\\n{\\\\displaystyle {\\\\begin{aligned}{\\\\text{Attention}}(Q,K,V)={\\\\text{softmax}}\\\\left({\\\\frac {QK^{\\\\mathrm {T} }}{\\\\sqrt {d_{k}}}}\\\\right)V\\\\end{aligned}}}\\n\\n\\nOne set of \\n\\n\\n\\n\\n(\\n\\n\\nW\\n\\nQ\\n\\n\\n,\\n\\nW\\n\\nK\\n\\n\\n,\\n\\nW\\n\\nV\\n\\n\\n\\n)\\n\\n\\n\\n{\\\\displaystyle \\\\left(W_{Q},W_{K},W_{V}\\\\right)}\\n\\n matrices is called an attention head, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, with multiple attention heads the model can do this for different definitions of \"relevance\". In addition the influence field representing relevance can become progressively dilated in successive layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, attention heads can attend mostly to the next word, while others  mainly attend from verbs to their direct objects.[8] The computations for each attention head can be performed in parallel, which allows for fast processing. The outputs for the attention layer are concatenated to pass into the feed-forward neural network layers.\\nEach encoder consists of two major components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism accepts input encodings from the previous encoder and weighs their relevance to each other to generate output encodings. The feed-forward neural network further processes each output encoding individually. These output encodings are then passed to the next encoder as its input, as well as to the decoders.\\nThe first encoder takes positional information and embeddings of the input sequence as its input, rather than encodings. The positional information is necessary for the transformer to make use of the order of the sequence, because no other part of the transformer makes use of this.[1]\\nEach decoder consists of three major components: a self-attention mechanism, an attention mechanism over the encodings, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders.[1][7]\\nLike the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow.[1] The last decoder is followed by a final linear transformation and softmax layer, to produce the output probabilities over the vocabulary.\\nTraining transformer-based architectures can be expensive, especially for long inputs.[9] Alternative architectures include the Reformer (which reduces the computational load from \\n\\n\\n\\nO\\n(\\n\\nN\\n\\n2\\n\\n\\n)\\n\\n\\n{\\\\displaystyle O(N^{2})}\\n\\n to \\n\\n\\n\\nO\\n(\\nN\\nln\\n\\u2061\\nN\\n)\\n\\n\\n{\\\\displaystyle O(N\\\\ln N)}\\n\\n), or models like ETC/BigBird (which can reduce it to \\n\\n\\n\\nO\\n(\\nN\\n)\\n\\n\\n{\\\\displaystyle O(N)}\\n\\n)[10] where \\n\\n\\n\\nN\\n\\n\\n{\\\\displaystyle N}\\n\\n is the length of the sequence. This is done using locality-sensitive hashing and reversible layers.[11][12]\\nA benchmark for comparing transformer architectures was introduced in late 2020.[13]\\nTransformers typically undergo semi-supervised learning involving unsupervised pretraining followed by supervised fine-tuning. Pretraining is typically done on a larger dataset than fine-tuning, due to the limited availability of labeled training data. Tasks for pretraining and fine-tuning commonly include:\\nThe transformer has had great success in natural language processing (NLP), for example the tasks of machine translation and time series prediction.[15]  Many pretrained models such as GPT-2, GPT-3, BERT, XLNet, and RoBERTa demonstrate the ability of transformers to perform a wide variety of such NLP-related tasks, and have the potential to find real-world applications.[4][5][16] These may include:\\nIn 2020, it was shown that the transformer architecture, more specifically GPT-2, could be tuned to play chess.[22] Transformers have been applied to image processing with results competitive with convolutional neural networks.[23][24]\\nThe transformer model has been implemented in standard deep learning frameworks such as TensorFlow and PyTorch.\\nTransformers is a library produced by Hugging Face that supplies transformer-based architectures and pretrained models.[3]\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNebVP3YzLpT"
      },
      "source": [
        "## **Text Preprocessing**\n",
        "#### Remove unwanted text & special characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Xs4os6ihWN"
      },
      "source": [
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdfJfCnLzZHw"
      },
      "source": [
        "####Sentences tokenization & calculate weighted frequencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLD1Mq1Jiyar"
      },
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords and word not in punctuation:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = pd.DataFrame(word_frequencies.items(), columns=['Keyword', 'Frequency'])\n",
        "word_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8_EllBzirM4F",
        "outputId": "2f23f79a-1ceb-43db-bd64-357df0b8b6dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Keyword  Frequency\n",
              "0              A          3\n",
              "1    transformer         16\n",
              "2           deep          3\n",
              "3       learning          4\n",
              "4          model         14\n",
              "..           ...        ...\n",
              "490      library          1\n",
              "491     produced          1\n",
              "492      Hugging          1\n",
              "493         Face          1\n",
              "494     supplies          1\n",
              "\n",
              "[495 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de348207-b07c-4725-ad4a-e77c21b417e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keyword</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transformer</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deep</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learning</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>model</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>library</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>produced</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>Hugging</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>Face</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>supplies</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>495 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de348207-b07c-4725-ad4a-e77c21b417e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de348207-b07c-4725-ad4a-e77c21b417e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de348207-b07c-4725-ad4a-e77c21b417e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efgx86zJpF6b"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTEwJZ-mpRpb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "65ce1096-1636-422e-fbd0-4bd1f3f6f6e2"
      },
      "source": [
        "word_weighted = pd.DataFrame(word_frequencies.items(), columns=['Keyword', 'Score'])\n",
        "word_weighted"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Keyword     Score\n",
              "0              A  0.068182\n",
              "1    transformer  0.363636\n",
              "2           deep  0.068182\n",
              "3       learning  0.090909\n",
              "4          model  0.318182\n",
              "..           ...       ...\n",
              "490      library  0.022727\n",
              "491     produced  0.022727\n",
              "492      Hugging  0.022727\n",
              "493         Face  0.022727\n",
              "494     supplies  0.022727\n",
              "\n",
              "[495 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83f7cebe-004a-4cc7-80f1-c13df02e3b0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keyword</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>0.068182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>transformer</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deep</td>\n",
              "      <td>0.068182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learning</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>model</td>\n",
              "      <td>0.318182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>library</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>produced</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>Hugging</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>Face</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>supplies</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>495 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83f7cebe-004a-4cc7-80f1-c13df02e3b0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83f7cebe-004a-4cc7-80f1-c13df02e3b0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83f7cebe-004a-4cc7-80f1-c13df02e3b0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip5afGww06no"
      },
      "source": [
        "## **Text Visualization** \n",
        "### Keywords weighted frequency distribution "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxvqKzwyqUwr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "f5d82f9f-ab07-4185-c2f9-36d399cc7d74"
      },
      "source": [
        "frequency_dist = nltk.FreqDist(word_frequencies)\n",
        "frequency_dist.plot(30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI51xLyS03D3"
      },
      "source": [
        "## **Text Manupulation** \n",
        "#### Calculate scores of each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0xfD_y3j_aG"
      },
      "source": [
        "sentence_scores = {}\n",
        "\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sentence_weighted = pd.DataFrame(sentence_scores.items(), columns=['Sentence', 'Score'])\n",
        "Sentence_weighted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XYiv7YhDTNv7",
        "outputId": "59d3d76b-1af3-4044-9a7f-cd1ecf1db558"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Sentence     Score\n",
              "0   A transformer is a deep learning model that ad...  1.795455\n",
              "1   It is used primarily in the fields of natural ...  0.522727\n",
              "2   Like recurrent neural networks (RNNs), transfo...  1.500000\n",
              "3   However, unlike RNNs, transformers do not nece...  0.500000\n",
              "4   Rather, the attention mechanism provides conte...  2.045455\n",
              "..                                                ...       ...\n",
              "60  Tasks for pretraining and fine-tuning commonly...  1.409091\n",
              "61  These may include: In 2020, it was shown that ...  0.704545\n",
              "62  Transformers have been applied to image proces...  0.590909\n",
              "63  The transformer model has been implemented in ...  0.909091\n",
              "64  Transformers is a library produced by Hugging ...  0.431818\n",
              "\n",
              "[65 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b75eca01-aaa9-4931-abe5-4de23df4e6db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A transformer is a deep learning model that ad...</td>\n",
              "      <td>1.795455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is used primarily in the fields of natural ...</td>\n",
              "      <td>0.522727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Like recurrent neural networks (RNNs), transfo...</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>However, unlike RNNs, transformers do not nece...</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rather, the attention mechanism provides conte...</td>\n",
              "      <td>2.045455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Tasks for pretraining and fine-tuning commonly...</td>\n",
              "      <td>1.409091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>These may include: In 2020, it was shown that ...</td>\n",
              "      <td>0.704545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Transformers have been applied to image proces...</td>\n",
              "      <td>0.590909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>The transformer model has been implemented in ...</td>\n",
              "      <td>0.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Transformers is a library produced by Hugging ...</td>\n",
              "      <td>0.431818</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b75eca01-aaa9-4931-abe5-4de23df4e6db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b75eca01-aaa9-4931-abe5-4de23df4e6db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b75eca01-aaa9-4931-abe5-4de23df4e6db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtT4HuGw1vK3"
      },
      "source": [
        "## **Text Summarization**\n",
        "#### Summarize the article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgdWs7xYkHw7"
      },
      "source": [
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "summary = ' '.join(summary_sentences)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import fill\n",
        "def formatItem(left, right):\n",
        "   wrapped = fill(right, width=100, subsequent_indent=' '*15)\n",
        "   return '  {0:<20}{1}'.format(left, wrapped)"
      ],
      "metadata": {
        "id": "N-ZN4cjP6zvC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatItem('\\033[1m' + 'Summarized Article:' + '\\033[0m' , summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF9eJpiS609y",
        "outputId": "d384245c-e7a5-4dd7-e8c9-4279dcf7c319"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1mSummarized Article:\u001b[0mEach decoder layer has an additional attention mechanism that draws information from the outputs of\n",
            "               previous decoders, before the decoder layer draws information from the encodings.\n",
            "               Transformers are built on these attention technologies without using an RNN\n",
            "               structure, highlighting the fact that attention mechanisms alone can match the\n",
            "               performance of RNNs with attention. While each attention head attends to the tokens\n",
            "               that are relevant to each token, with multiple attention heads the model can do this\n",
            "               for different definitions of \"relevance\". Transformers use an attention mechanism\n",
            "               without an RNN, processing all tokens at the same time and calculating attention\n",
            "               weights between them in successive layers. q i ⋅ k j {\\displaystyle q_{i}\\cdot k_{j}}\n",
            "               is large), this does not necessarily mean that token j {\\displaystyle j} will attend\n",
            "               to token i {\\displaystyle i} (i.e. The decoder functions in a similar fashion to the\n",
            "               encoder, but an additional attention mechanism is inserted which instead draws\n",
            "               relevant information from the encodings generated by the encoders. When a sentence is\n",
            "               passed into a transformer model, attention weights are calculated between every token\n",
            "               simultaneously.\n"
          ]
        }
      ]
    }
  ]
}